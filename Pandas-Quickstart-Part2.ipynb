{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**\n",
    "   - Handling missing data (dropna, fillna)\n",
    "\n",
    "\n",
    "   Handling missing data is an important aspect of data cleaning in pandas. Two common methods are **`dropna`** and **`fillna`**. Here's an easy explanation for both:\n",
    "\n",
    "### `dropna`\n",
    "\n",
    "**`dropna`** is used to **remove** rows or columns that contain missing values (NaNs).\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "1. **Remove rows with any NaN values:**\n",
    "   ```python\n",
    "   df.dropna()\n",
    "   ```\n",
    "   This will remove all rows that have at least one NaN value.\n",
    "\n",
    "2. **Remove columns with any NaN values:**\n",
    "   ```python\n",
    "   df.dropna(axis=1)\n",
    "   ```\n",
    "   This will remove all columns that have at least one NaN value.\n",
    "\n",
    "3. **Remove rows where all elements are NaN:**\n",
    "   ```python\n",
    "   df.dropna(how='all')\n",
    "   ```\n",
    "   This will only remove rows where all the elements are NaN.\n",
    "\n",
    "### `fillna`\n",
    "\n",
    "**`fillna`** is used to **fill** missing values with a specified value or a method.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "1. **Fill NaN with a specific value:**\n",
    "   ```python\n",
    "   df.fillna(0)\n",
    "   ```\n",
    "   This will replace all NaN values with 0.\n",
    "\n",
    "2. **Fill NaN with the mean of the column:**\n",
    "   ```python\n",
    "   df.fillna(df.mean())\n",
    "   ```\n",
    "   This will replace NaN values with the mean of their respective column.\n",
    "\n",
    "3. **Forward fill (propagate the last valid observation forward):**\n",
    "   ```python\n",
    "   df.fillna(method='ffill')\n",
    "   ```\n",
    "   This will replace NaN values with the last valid observation.\n",
    "\n",
    "4. **Backward fill (propagate the next valid observation backward):**\n",
    "   ```python\n",
    "   df.fillna(method='bfill')\n",
    "   ```\n",
    "   This will replace NaN values with the next valid observation.\n",
    "\n",
    "### Examples in Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  NaN  3.0  3.0\n",
      "3  4.0  4.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# Example DataFrame:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [np.nan, 2, 3, 4],\n",
    "    'C': [1, 2, 3, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "1  2.0  2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "#Using `dropna`:\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  0.0  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  0.0  3.0  3.0\n",
      "3  4.0  4.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# Using `fillna`:\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - **Data type conversions**\n",
    "\n",
    "Converting data types in pandas is a common task, especially when you need to ensure that your data is in the correct format for analysis. Hereâ€™s an easy guide to data type conversions in pandas.\n",
    "\n",
    "### **Basic Data Type Conversions**\n",
    "\n",
    "#### **1. Converting a Single Column**\n",
    "\n",
    "To convert the data type of a single column, you can use the `astype` method.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': ['1', '2', '3', '4']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert column A to integer\n",
    "df['A'] = df['A'].astype(int)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Converting Multiple Columns**\n",
    "\n",
    "You can convert multiple columns by applying `astype` on a subset of the DataFrame.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A      int64\n",
      "B    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {'A': ['1', '2', '3', '4'], 'B': ['5.1', '6.2', '7.3', '8.4']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert columns A to integer and B to float\n",
    "df = df.astype({'A': int, 'B': float})\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advanced Data Type Conversions**\n",
    "\n",
    "#### **1. Converting to Categorical**\n",
    "\n",
    "Categorical data types can save memory and are useful for variables that have a fixed number of distinct values.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    category\n",
      "dtype: object\n",
      "Index(['bird', 'cat', 'dog'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = {'A': ['cat', 'dog', 'cat', 'bird']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert column A to categorical\n",
    "df['A'] = df['A'].astype('category')\n",
    "print(df.dtypes)\n",
    "print(df['A'].cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Converting to Datetime**\n",
    "\n",
    "Datetime conversion is essential for time series analysis.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {'A': ['2021-01-01', '2021-02-01', '2021-03-01']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert column A to datetime\n",
    "df['A'] = pd.to_datetime(df['A'])\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Conversion Errors**\n",
    "\n",
    "If the data has some values that cannot be converted, you can use `errors='coerce'` to handle them. This will replace unconvertible values with `NaT` for dates or `NaN` for numbers.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  NaN\n",
      "3  4.0\n"
     ]
    }
   ],
   "source": [
    "data = {'A': ['1', '2', 'three', '4']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert column A to integer, invalid parsing will be set as NaN\n",
    "\n",
    "df['A'] = pd.to_numeric(df['A'], errors='coerce')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking Data Types**\n",
    "\n",
    "To see the data types of all columns in a DataFrame, you can use the `dtypes` attribute.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    object\n",
      "B    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {'A': ['1', '2', '3', '4'], 'B': ['5.1', '6.2', '7.3', '8.4']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By mastering these data type conversion techniques, you can ensure that your DataFrame has the appropriate types for effective analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Duplicates (duplicated, drop_duplicates)**\n",
    "\n",
    "Handling duplicates in a DataFrame is essential to ensure data integrity and accuracy. Pandas provides methods like **`duplicated`** and **`drop_duplicates`** to manage duplicate data easily.\n",
    "\n",
    "### **Checking for Duplicates: `duplicated`**\n",
    "\n",
    "The **`duplicated`** method returns a boolean Series indicating whether each row is a duplicate.\n",
    "\n",
    "#### **Examples:**\n",
    "\n",
    "1. **Identify all duplicate rows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 2, 4, 5, 5],\n",
    "           'B': ['a', 'b', 'b', 'd', 'e', 'e']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will print a Series where `True` indicates the row is a duplicate.\n",
    "\n",
    "2. **Identify duplicate rows based on a specific column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in column 'A'\n",
    "duplicates_in_A = df.duplicated(subset=['A'])\n",
    "print(duplicates_in_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   This will print a Series indicating duplicates based on column 'A'.\n",
    "\n",
    "### **Removing Duplicates: `drop_duplicates`**\n",
    "\n",
    "The **`drop_duplicates`** method removes duplicate rows from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Examples:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Remove all duplicate rows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Drop all duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(df_no_duplicates)\n",
    "\n",
    "#This will remove all rows that are duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Remove duplicate rows based on specific columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on column 'A'\n",
    "df_no_duplicates_in_A = df.drop_duplicates(subset=['A'])\n",
    "print(df_no_duplicates_in_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will remove duplicates based on column 'A'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Keep the last occurrence of the duplicate row:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  a\n",
      "2  2  b\n",
      "3  4  d\n",
      "5  5  e\n"
     ]
    }
   ],
   "source": [
    "# Keep the last occurrence of duplicate rows\n",
    "df_keep_last = df.drop_duplicates(keep='last')\n",
    "print(df_keep_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By default, `keep='first'` retains the first occurrence. Using `keep='last'` retains the last occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example in Practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "2  2  b\n",
      "3  4  d\n",
      "4  5  e\n",
      "5  5  e\n"
     ]
    }
   ],
   "source": [
    "# Example DataFrame:\n",
    "data = {'A': [1, 2, 2, 4, 5, 5],\n",
    "        'B': ['a', 'b', 'b', 'd', 'e', 'e']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `duplicated`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows (True indicates a duplicate):\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "print(\"\\nDuplicate rows (True indicates a duplicate):\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `drop_duplicates`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping duplicates:\n",
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Drop all duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"\\nDataFrame after dropping duplicates:\")\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicates based on a specific column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping duplicates based on column 'A':\n",
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on column 'A'\n",
    "df_no_duplicates_in_A = df.drop_duplicates(subset=['A'])\n",
    "print(\"\\nDataFrame after dropping duplicates based on column 'A':\")\n",
    "print(df_no_duplicates_in_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using these methods, you can effectively manage duplicates in your DataFrame to ensure clean and reliable data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **String operations**\n",
    "\n",
    "String operations in pandas are essential for manipulating and analyzing textual data. Pandas provides a variety of string methods accessible via the `.str` accessor, making it easy to perform complex string operations on DataFrame columns.\n",
    "\n",
    "### **Basic String Operations**\n",
    "\n",
    "#### **1. Converting to Lowercase and Uppercase**\n",
    "\n",
    "- **Lowercase:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': ['Hello', 'World', 'Pandas', 'DataFrame']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower\n",
      "0      Hello      hello\n",
      "1      World      world\n",
      "2     Pandas     pandas\n",
      "3  DataFrame  dataframe\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "df['A_lower'] = df['A'].str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Uppercase:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper\n",
      "0      Hello      hello      HELLO\n",
      "1      World      world      WORLD\n",
      "2     Pandas     pandas     PANDAS\n",
      "3  DataFrame  dataframe  DATAFRAME\n"
     ]
    }
   ],
   "source": [
    "# Convert to uppercase\n",
    "df['A_upper'] = df['A'].str.upper()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. String Length**\n",
    "\n",
    "- **Calculate length of each string:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper  A_length\n",
      "0      Hello      hello      HELLO         5\n",
      "1      World      world      WORLD         5\n",
      "2     Pandas     pandas     PANDAS         6\n",
      "3  DataFrame  dataframe  DATAFRAME         9\n"
     ]
    }
   ],
   "source": [
    "# Calculate string length\n",
    "df['A_length'] = df['A'].str.len()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. String Splitting**\n",
    "\n",
    "- **Split strings into lists:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper  A_length      A_split\n",
      "0      Hello      hello      HELLO         5      [Hello]\n",
      "1      World      world      WORLD         5      [World]\n",
      "2     Pandas     pandas     PANDAS         6     [Pandas]\n",
      "3  DataFrame  dataframe  DATAFRAME         9  [DataFrame]\n"
     ]
    }
   ],
   "source": [
    "# Split strings by a space\n",
    "df['A_split'] = df['A'].str.split(' ')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Expand split strings into separate columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "0      Hello\n",
      "1      World\n",
      "2     Pandas\n",
      "3  DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Split strings and expand into separate columns\n",
    "df_split = df['A'].str.split(' ', expand=True)\n",
    "print(df_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advanced String Operations**\n",
    "\n",
    "#### **1. Extracting Substrings**\n",
    "- **Extract first 3 characters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper  A_length      A_split A_substring\n",
      "0      Hello      hello      HELLO         5      [Hello]         Hel\n",
      "1      World      world      WORLD         5      [World]         Wor\n",
      "2     Pandas     pandas     PANDAS         6     [Pandas]         Pan\n",
      "3  DataFrame  dataframe  DATAFRAME         9  [DataFrame]         Dat\n"
     ]
    }
   ],
   "source": [
    "# Extract first 3 characters\n",
    "df['A_substring'] = df['A'].str[:3]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Extract specific patterns using regex:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper  A_length      A_split A_substring A_digits\n",
      "0      Hello      hello      HELLO         5      [Hello]         Hel      NaN\n",
      "1      World      world      WORLD         5      [World]         Wor      NaN\n",
      "2     Pandas     pandas     PANDAS         6     [Pandas]         Pan      NaN\n",
      "3  DataFrame  dataframe  DATAFRAME         9  [DataFrame]         Dat      NaN\n"
     ]
    }
   ],
   "source": [
    "  # Extract digits using regex\n",
    "  df['A_digits'] = df['A'].str.extract('(\\n)')\n",
    "  print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Replacing Substrings**\n",
    "- **Replace substrings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper  A_length      A_split A_substring  \\\n",
      "0      Hello      hello      HELLO         5      [Hello]         Hel   \n",
      "1      World      world      WORLD         5      [World]         Wor   \n",
      "2     Pandas     pandas     PANDAS         6     [Pandas]         Pan   \n",
      "3  DataFrame  dataframe  DATAFRAME         9  [DataFrame]         Dat   \n",
      "\n",
      "  A_digits  A_replace  \n",
      "0      NaN      Hello  \n",
      "1      NaN      World  \n",
      "2      NaN     Pondos  \n",
      "3      NaN  DotoFrome  \n"
     ]
    }
   ],
   "source": [
    "# Replace 'a' with 'o'\n",
    "df['A_replace'] = df['A'].str.replace('a', 'o')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Replace using regex:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A    A_lower    A_upper  A_length      A_split A_substring  \\\n",
      "0      Hello      hello      HELLO         5      [Hello]         Hel   \n",
      "1      World      world      WORLD         5      [World]         Wor   \n",
      "2     Pandas     pandas     PANDAS         6     [Pandas]         Pan   \n",
      "3  DataFrame  dataframe  DATAFRAME         9  [DataFrame]         Dat   \n",
      "\n",
      "  A_digits  A_replace A_replace_digits  \n",
      "0      NaN      Hello            Hello  \n",
      "1      NaN      World            World  \n",
      "2      NaN     Pondos           Pandas  \n",
      "3      NaN  DotoFrome        DataFrame  \n"
     ]
    }
   ],
   "source": [
    "# Replace digits with an empty string\n",
    "df['A_replace_digits'] = df['A'].str.replace('\\n', '', regex=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example in Practice**\n",
    "#### Example DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "            A\n",
      "0    Hello123\n",
      "1    World456\n",
      "2   Pandas789\n",
      "3  DataFrame0\n"
     ]
    }
   ],
   "source": [
    "data = {'A': ['Hello123', 'World456', 'Pandas789', 'DataFrame0']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase and Uppercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Lowercase and Uppercase:\n",
      "            A     A_lower     A_upper\n",
      "0    Hello123    hello123    HELLO123\n",
      "1    World456    world456    WORLD456\n",
      "2   Pandas789   pandas789   PANDAS789\n",
      "3  DataFrame0  dataframe0  DATAFRAME0\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "df['A_lower'] = df['A'].str.lower()\n",
    "# Convert to uppercase\n",
    "df['A_upper'] = df['A'].str.upper()\n",
    "print(\"\\nDataFrame with Lowercase and Uppercase:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with String Length:\n",
      "            A     A_lower     A_upper  A_length\n",
      "0    Hello123    hello123    HELLO123         8\n",
      "1    World456    world456    WORLD456         8\n",
      "2   Pandas789   pandas789   PANDAS789         9\n",
      "3  DataFrame0  dataframe0  DATAFRAME0        10\n"
     ]
    }
   ],
   "source": [
    "# Calculate string length\n",
    "df['A_length'] = df['A'].str.len()\n",
    "print(\"\\nDataFrame with String Length:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Split Strings:\n",
      "            A     A_lower     A_upper  A_length       A_split\n",
      "0    Hello123    hello123    HELLO123         8    [Hello123]\n",
      "1    World456    world456    WORLD456         8    [World456]\n",
      "2   Pandas789   pandas789   PANDAS789         9   [Pandas789]\n",
      "3  DataFrame0  dataframe0  DATAFRAME0        10  [DataFrame0]\n"
     ]
    }
   ],
   "source": [
    "# Split strings by digits\n",
    "df['A_split'] = df['A'].str.split('\\n')\n",
    "print(\"\\nDataFrame with Split Strings:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Substrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Extracted Substrings:\n",
      "            A     A_lower     A_upper  A_length       A_split A_substring\n",
      "0    Hello123    hello123    HELLO123         8    [Hello123]       Hello\n",
      "1    World456    world456    WORLD456         8    [World456]       World\n",
      "2   Pandas789   pandas789   PANDAS789         9   [Pandas789]       Panda\n",
      "3  DataFrame0  dataframe0  DATAFRAME0        10  [DataFrame0]       DataF\n"
     ]
    }
   ],
   "source": [
    "# Extract first 5 characters\n",
    "df['A_substring'] = df['A'].str[:5]\n",
    "print(\"\\nDataFrame with Extracted Substrings:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing Substrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with Replaced Substrings:\n",
      "            A     A_lower     A_upper  A_length       A_split A_substring  \\\n",
      "0    Hello123    hello123    HELLO123         8    [Hello123]       Hello   \n",
      "1    World456    world456    WORLD456         8    [World456]       World   \n",
      "2   Pandas789   pandas789   PANDAS789         9   [Pandas789]       Panda   \n",
      "3  DataFrame0  dataframe0  DATAFRAME0        10  [DataFrame0]       DataF   \n",
      "\n",
      "  A_replace_digits  \n",
      "0         Hello123  \n",
      "1         World456  \n",
      "2        Pandas789  \n",
      "3       DataFrame0  \n"
     ]
    }
   ],
   "source": [
    "# Replace digits with '#'\n",
    "df['A_replace_digits'] = df['A'].str.replace('\\n', '#', regex=True)\n",
    "print(\"\\nDataFrame with Replaced Substrings:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Manipulation**\n",
    "## - Merging, joining, and concatenating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Merging**\n",
    "\n",
    "**Merging** DataFrames is like combining tables in a database. You merge DataFrames based on a common column, which is called a key.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value1  value2\n",
      "0   A       1       4\n",
      "1   B       2       5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value2': [4, 5, 6]})\n",
    "\n",
    "# Merge the DataFrames on the 'key' column\n",
    "merged_df = pd.merge(df1, df2, on='key')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the `merge` function combines `df1` and `df2` where the `key` column matches.\n",
    "\n",
    "**Types of Merges:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inner Merge:** Keeps only the rows with keys that are in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  value1  value2\n",
       "0   A       1       4\n",
       "1   B       2       5"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on='key', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Outer Merge:** Keeps all rows, filling with NaNs where there are no matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  value1  value2\n",
       "0   A     1.0     4.0\n",
       "1   B     2.0     5.0\n",
       "2   C     3.0     NaN\n",
       "3   D     NaN     6.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Left Merge:** Keeps all rows from the left DataFrame, filling with NaNs from the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  value1  value2\n",
       "0   A       1     4.0\n",
       "1   B       2     5.0\n",
       "2   C       3     NaN"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Right Merge:** Keeps all rows from the right DataFrame, filling with NaNs from the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key  value1  value2\n",
       "0   A     1.0       4\n",
       "1   B     2.0       5\n",
       "2   D     NaN       6"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on='key', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Joining**\n",
    "\n",
    "**Joining** is similar to merging but is based on the indexes of the DataFrames.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two sample DataFrames with indexes\n",
    "df1 = pd.DataFrame({'value1': [1, 2, 3]}, index=['A', 'B', 'C'])\n",
    "df2 = pd.DataFrame({'value2': [4, 5, 6]}, index=['A', 'B', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value1  value2\n",
      "A       1     4.0\n",
      "B       2     5.0\n",
      "C       3     NaN\n"
     ]
    }
   ],
   "source": [
    "# Join the DataFrames on their indexes\n",
    "joined_df = df1.join(df2, lsuffix='_left', rsuffix='_right')\n",
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the `join` function combines `df1` and `df2` based on their indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Joins:**\n",
    "- **Left Join (default):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value1  value2\n",
       "A       1     4.0\n",
       "B       2     5.0\n",
       "C       3     NaN"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Right Join:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value1  value2\n",
       "A     1.0       4\n",
       "B     2.0       5\n",
       "D     NaN       6"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.join(df2, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inner Join:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value1  value2\n",
       "A       1       4\n",
       "B       2       5"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.join(df2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Outer Join:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value1  value2\n",
       "A     1.0     4.0\n",
       "B     2.0     5.0\n",
       "C     3.0     NaN\n",
       "D     NaN     6.0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.join(df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Concatenating**\n",
    "\n",
    "**Concatenating** is like stacking DataFrames either vertically or horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "0  A3  B3\n",
      "1  A4  B4\n",
      "2  A5  B5\n"
     ]
    }
   ],
   "source": [
    "#### Example:\n",
    "\n",
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']})\n",
    "df2 = pd.DataFrame({'A': ['A3', 'A4', 'A5'], 'B': ['B3', 'B4', 'B5']})\n",
    "\n",
    "# Concatenate the DataFrames along rows (axis=0)\n",
    "concat_df = pd.concat([df1, df2], axis=0)\n",
    "print(concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the `concat` function stacks `df1` and `df2` vertically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate along columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   A   B\n",
      "0  A0  B0  A3  B3\n",
      "1  A1  B1  A4  B4\n",
      "2  A2  B2  A5  B5\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along columns (axis=1)\n",
    "concat_cols_df = pd.concat([df1, df2], axis=1)\n",
    "print(concat_cols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate with keys:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A   B\n",
      "df1 0  A0  B0\n",
      "    1  A1  B1\n",
      "    2  A2  B2\n",
      "df2 0  A3  B3\n",
      "    1  A4  B4\n",
      "    2  A5  B5\n"
     ]
    }
   ],
   "source": [
    "# Concatenate with keys to identify source DataFrame\n",
    "concat_keys_df = pd.concat([df1, df2], keys=['df1', 'df2'])\n",
    "print(concat_keys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***By understanding these methods, you can effectively combine and manipulate DataFrames in pandas to suit your analysis needs.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # **Reshaping data (pivot, melt)**\n",
    "\n",
    "Reshaping data in pandas is useful for changing the layout of your DataFrame. Two key functions for reshaping are **pivot** and **melt**. Hereâ€™s how to use them, explained in a way thatâ€™s easy to understand for beginners.\n",
    "\n",
    "### Pivot\n",
    "\n",
    "**Pivot** is used to transform or reshape data where columns become rows and rows become columns. Itâ€™s often used to create a new DataFrame from an existing one by specifying an index, columns, and values.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city        Los Angeles  New York\n",
      "date                             \n",
      "2021-01-01           75        32\n",
      "2021-01-02           77        30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02'],\n",
    "        'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "        'temperature': [32, 75, 30, 77]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = df.pivot(index='date', columns='city', values='temperature')\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "- The `index` is set to 'date'.\n",
    "- The `columns` are set to 'city'.\n",
    "- The `values` are the 'temperature'.\n",
    "\n",
    "This creates a new DataFrame where dates are the index and cities are the columns, showing the temperature for each city on each date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt\n",
    "\n",
    "**Melt** is used to convert a DataFrame from wide format to long format. Itâ€™s the opposite of pivot and is useful when you want to unpivot your data to make it easier to plot or analyze.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date         city  temperature\n",
      "0  2021-01-01     New York           32\n",
      "1  2021-01-02     New York           30\n",
      "2  2021-01-01  Los Angeles           75\n",
      "3  2021-01-02  Los Angeles           77\n"
     ]
    }
   ],
   "source": [
    "# Create a sample DataFrame\n",
    "data = {'date': ['2021-01-01', '2021-01-02'],\n",
    "        'New York': [32, 30],\n",
    "        'Los Angeles': [75, 77]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame\n",
    "melt_df = pd.melt(df, id_vars=['date'], value_vars=['New York', 'Los Angeles'],\n",
    "                  var_name='city', value_name='temperature')\n",
    "print(melt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "- The `id_vars` is set to 'date', which means it will remain as an identifier.\n",
    "- The `value_vars` are 'New York' and 'Los Angeles', which are the columns to unpivot.\n",
    "- The `var_name` is set to 'city', which will hold the column names.\n",
    "- The `value_name` is set to 'temperature', which will hold the values.\n",
    "\n",
    "This transforms the DataFrame into a long format where each row represents a single observation of temperature for a city on a given date.\n",
    "\n",
    "### Putting It All Together\n",
    "\n",
    "#### Example DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         date         city  temperature\n",
      "0  2021-01-01     New York           32\n",
      "1  2021-01-01  Los Angeles           75\n",
      "2  2021-01-02     New York           30\n",
      "3  2021-01-02  Los Angeles           77\n"
     ]
    }
   ],
   "source": [
    "data = {'date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02'],\n",
    "        'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "        'temperature': [32, 75, 30, 77]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivoted DataFrame:\n",
      "city        Los Angeles  New York\n",
      "date                             \n",
      "2021-01-01           75        32\n",
      "2021-01-02           77        30\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df.pivot(index='date', columns='city', values='temperature')\n",
    "print(\"\\nPivoted DataFrame:\")\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melted DataFrame:\n",
      "         date         city  temperature\n",
      "0  2021-01-01     New York           32\n",
      "1  2021-01-02     New York           30\n",
      "2  2021-01-01  Los Angeles           75\n",
      "3  2021-01-02  Los Angeles           77\n"
     ]
    }
   ],
   "source": [
    "# Create a wide format DataFrame to melt\n",
    "wide_df = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'],\n",
    "                        'New York': [32, 30],\n",
    "                        'Los Angeles': [75, 77]})\n",
    "\n",
    "melt_df = pd.melt(wide_df, id_vars=['date'], value_vars=['New York', 'Los Angeles'],\n",
    "                  var_name='city', value_name='temperature')\n",
    "print(\"\\nMelted DataFrame:\")\n",
    "print(melt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***By understanding pivot and melt, you can reshape your data to fit your analysis needs better, making it easier to visualize and work with.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Grouping data (groupby, aggregation functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping data is essential for summarizing and analyzing large datasets. Pandas provides the **`groupby`** method to group data by one or more columns, and then apply aggregation functions to summarize the data.\n",
    "\n",
    "### Grouping Data with `groupby`\n",
    "\n",
    "The **`groupby`** method is used to split the data into groups based on some criteria, then apply a function to each group independently.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "          city        date  temperature  humidity\n",
      "0     New York  2021-01-01           32        80\n",
      "1  Los Angeles  2021-01-01           75        20\n",
      "2     New York  2021-01-02           30        85\n",
      "3  Los Angeles  2021-01-02           77        30\n",
      "4     New York  2021-01-03           28        75\n",
      "5  Los Angeles  2021-01-03           78        25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "        'date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02', '2021-01-03', '2021-01-03'],\n",
    "        'temperature': [32, 75, 30, 77, 28, 78],\n",
    "        'humidity': [80, 20, 85, 30, 75, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'city'\n",
    "grouped = df.groupby('city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the DataFrame `df` is grouped by the 'city' column.\n",
    "\n",
    "### Aggregation Functions\n",
    "\n",
    "Once the data is grouped, you can apply various aggregation functions to summarize the data.\n",
    "\n",
    "#### Common Aggregation Functions:\n",
    "\n",
    "- **Mean:** Calculate the average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of grouped data:\n",
      "             temperature  humidity\n",
      "city                              \n",
      "Los Angeles    76.666667      25.0\n",
      "New York       30.000000      80.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean for numeric columns\n",
    "mean_df = grouped[['temperature', 'humidity']].mean()\n",
    "print(\"\\nMean of grouped data:\")\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Sum:** Calculate the total value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date  temperature\n",
      "city                                          \n",
      "Los Angeles  2021-01-012021-01-02          152\n",
      "New York     2021-01-012021-01-02           62\n"
     ]
    }
   ],
   "source": [
    "sum_df = grouped.sum()\n",
    "print(sum_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Count:** Count the number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  temperature\n",
      "city                          \n",
      "Los Angeles     2            2\n",
      "New York        2            2\n"
     ]
    }
   ],
   "source": [
    "count_df = grouped.count()\n",
    "print(count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Max:** Find the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  temperature\n",
      "city                                \n",
      "Los Angeles  2021-01-02           77\n",
      "New York     2021-01-02           32\n"
     ]
    }
   ],
   "source": [
    "max_df = grouped.max()\n",
    "print(max_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Min:** Find the minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  temperature\n",
      "city                                \n",
      "Los Angeles  2021-01-01           75\n",
      "New York     2021-01-01           30\n"
     ]
    }
   ],
   "source": [
    "min_df = grouped.min()\n",
    "print(min_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Multiple Aggregation Functions\n",
    "\n",
    "You can apply multiple aggregation functions using the **`agg`** method.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            temperature     humidity    \n",
      "                   mean max      min max\n",
      "city                                    \n",
      "Los Angeles   76.666667  78       20  30\n",
      "New York      30.000000  32       75  85\n"
     ]
    }
   ],
   "source": [
    "# Apply multiple aggregation functions\n",
    "agg_df = grouped.agg({'temperature': ['mean', 'max'], 'humidity': ['min', 'max']})\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we calculate the mean and max for temperature and the min and max for humidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Multiple Columns\n",
    "\n",
    "You can also group by multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        temperature  humidity\n",
      "city        date                             \n",
      "Los Angeles 2021-01-01         75.0      20.0\n",
      "            2021-01-02         77.0      30.0\n",
      "            2021-01-03         78.0      25.0\n",
      "New York    2021-01-01         32.0      80.0\n",
      "            2021-01-02         30.0      85.0\n",
      "            2021-01-03         28.0      75.0\n"
     ]
    }
   ],
   "source": [
    "#### Example:\n",
    "\n",
    "# Group by 'city' and 'date'\n",
    "multi_grouped = df.groupby(['city', 'date'])\n",
    "\n",
    "# Calculate the mean for each group\n",
    "multi_mean_df = multi_grouped.mean()\n",
    "print(multi_mean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the DataFrame is grouped by both 'city' and 'date', and the mean is calculated for each group.\n",
    "\n",
    "### Custom Aggregation Functions\n",
    "\n",
    "You can apply custom aggregation functions by defining your own functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             temperature  humidity\n",
      "city                              \n",
      "Los Angeles            3        10\n",
      "New York               4        10\n"
     ]
    }
   ],
   "source": [
    "#### Example:\n",
    "# Define a custom function\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Apply the custom function\n",
    "custom_agg_df = grouped.agg({'temperature': range_func, 'humidity': range_func})\n",
    "print(custom_agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we define a custom function to calculate the range (max - min) and apply it to the grouped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "          city        date  temperature  humidity\n",
      "0     New York  2021-01-01           32        80\n",
      "1  Los Angeles  2021-01-01           75        20\n",
      "2     New York  2021-01-02           30        85\n",
      "3  Los Angeles  2021-01-02           77        30\n",
      "4     New York  2021-01-03           28        75\n",
      "5  Los Angeles  2021-01-03           78        25\n"
     ]
    }
   ],
   "source": [
    "#### Example DataFrame:\n",
    "\n",
    "data = {'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "        'date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02', '2021-01-03', '2021-01-03'],\n",
    "        'temperature': [32, 75, 30, 77, 28, 78],\n",
    "        'humidity': [80, 20, 85, 30, 75, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'city'\n",
    "grouped = df.groupby('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of grouped data:\n",
      "             temperature  humidity\n",
      "city                              \n",
      "Los Angeles    76.666667      25.0\n",
      "New York       30.000000      80.0\n"
     ]
    }
   ],
   "source": [
    "mean_df = grouped[['temperature', 'humidity']].mean()\n",
    "print(\"\\nMean of grouped data:\")\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple aggregation functions:\n",
      "            temperature     humidity    \n",
      "                   mean max      min max\n",
      "city                                    \n",
      "Los Angeles   76.666667  78       20  30\n",
      "New York      30.000000  32       75  85\n"
     ]
    }
   ],
   "source": [
    "# Apply multiple aggregation functions\n",
    "agg_df = grouped.agg({'temperature': ['mean', 'max'], 'humidity': ['min', 'max']})\n",
    "print(\"\\nMultiple aggregation functions:\")\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'city' and 'date'\n",
    "multi_grouped = df.groupby(['city', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of grouped data by 'city' and 'date':\n",
      "                        temperature  humidity\n",
      "city        date                             \n",
      "Los Angeles 2021-01-01         75.0      20.0\n",
      "            2021-01-02         77.0      30.0\n",
      "            2021-01-03         78.0      25.0\n",
      "New York    2021-01-01         32.0      80.0\n",
      "            2021-01-02         30.0      85.0\n",
      "            2021-01-03         28.0      75.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean for each group\n",
    "multi_mean_df = multi_grouped.mean()\n",
    "print(\"\\nMean of grouped data by 'city' and 'date':\")\n",
    "print(multi_mean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***By understanding how to group and aggregate data, you can efficiently summarize and analyze large datasets in pandas.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # **Applying functions (apply, map)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Functions in Pandas: `apply` and `map`\n",
    "\n",
    "Pandas provides powerful methods like `apply` and `map` to apply functions to your data. These methods allow you to perform operations on DataFrame or Series objects easily.\n",
    "\n",
    "### Using `apply` on a DataFrame\n",
    "\n",
    "The `apply` method can be used to apply a function along either axis of the DataFrame (rows or columns).\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying function to each column:\n",
      "    A     B\n",
      "0   1   100\n",
      "1   4   400\n",
      "2   9   900\n",
      "3  16  1600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3, 4], 'B': [10, 20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply a function to each column\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "result = df.apply(square)\n",
    "print(\"Applying function to each column:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the `square` function is applied to each element in the DataFrame, squaring each value.\n",
    "\n",
    "### Using `apply` on a Series\n",
    "\n",
    "The `apply` method can also be used on a Series to apply a function to each element.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying function to each element of Series:\n",
      "0    11\n",
      "1    12\n",
      "2    13\n",
      "3    14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [1, 2, 3, 4]\n",
    "s = pd.Series(data)\n",
    "\n",
    "# Apply a function to each element\n",
    "result = s.apply(lambda x: x + 10)\n",
    "print(\"Applying function to each element of Series:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a lambda function is used to add 10 to each element of the Series.\n",
    "\n",
    "### Using `map` on a Series\n",
    "\n",
    "The `map` method is used to apply a function to each element of a Series. It is similar to `apply` but works only on Series objects.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping function to each element of Series:\n",
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "3    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [1, 2, 3, 4]\n",
    "s = pd.Series(data)\n",
    "\n",
    "# Map a function to each element\n",
    "result = s.map(lambda x: x * 2)\n",
    "print(\"Mapping function to each element of Series:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, a lambda function is used to multiply each element of the Series by 2.\n",
    "\n",
    "### Using `applymap` on a DataFrame\n",
    "\n",
    "The `applymap` method is used to apply a function to each element of the DataFrame.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying function to each element of DataFrame:\n",
      "     A    B\n",
      "0  101  110\n",
      "1  102  120\n",
      "2  103  130\n",
      "3  104  140\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3, 4], 'B': [10, 20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply a function to each element of the DataFrame\n",
    "result = df.map(lambda x: x + 100)\n",
    "print(\"Applying function to each element of DataFrame:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, a lambda function is used to add 100 to each element of the DataFrame.\n",
    "\n",
    "### Putting It All Together\n",
    "\n",
    "Here is a complete code example that demonstrates the use of `apply`, `map`, and `applymap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4], 'B': [10, 20, 30, 40]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply\n",
    "def square(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying function to each column:\n",
      "    A     B\n",
      "0   1   100\n",
      "1   4   400\n",
      "2   9   900\n",
      "3  16  1600\n"
     ]
    }
   ],
   "source": [
    "# Apply a function to each column of the DataFrame\n",
    "result_apply = df.apply(square)\n",
    "print(\"Applying function to each column:\")\n",
    "print(result_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Series\n",
    "s = pd.Series([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying function to each element of Series:\n",
      "0    11\n",
      "1    12\n",
      "2    13\n",
      "3    14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply a function to each element of the Series\n",
    "result_apply_series = s.apply(lambda x: x + 10)\n",
    "print(\"\\nApplying function to each element of Series:\")\n",
    "print(result_apply_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mapping function to each element of Series:\n",
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "3    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map a function to each element of the Series\n",
    "result_map = s.map(lambda x: x * 2)\n",
    "print(\"\\nMapping function to each element of Series:\")\n",
    "print(result_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying function to each element of DataFrame:\n",
      "     A    B\n",
      "0  101  110\n",
      "1  102  120\n",
      "2  103  130\n",
      "3  104  140\n"
     ]
    }
   ],
   "source": [
    "# Apply a function to each element of the DataFrame\n",
    "result_applymap = df.map(lambda x: x + 100)\n",
    "print(\"\\nApplying function to each element of DataFrame:\")\n",
    "print(result_applymap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***By using these methods, you can efficiently apply custom functions to your data in Pandas.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
